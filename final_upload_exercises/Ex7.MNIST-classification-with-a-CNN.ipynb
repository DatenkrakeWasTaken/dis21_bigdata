{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.th-koeln.de/img/logo.svg\" style=\"float: right;\" width=\"200\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7th exercise: <font color=\"#C70039\">MNIST Classification with a Convolutional Neural Network</font>\n",
    "* Course: DIS21a.1\n",
    "* Lecturer: <a href=\"https://www.gernotheisenberg.de/\">Gernot Heisenberg</a>\n",
    "* Author of notebook modifications and adaptations: <a href=\"https://www.gernotheisenberg.de/\">Gernot Heisenberg</a>\n",
    "* Student: Maximilian Pekarski\n",
    "* Matriculation number: 11120099\n",
    "* Date:   16.01.2023\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1250/1*vkQ0hXDaQv57sALXAJquxA.jpeg\" style=\"float: center;\" width=\"600\">\n",
    "\n",
    "---------------------------------\n",
    "**GENERAL NOTE 1**: \n",
    "Please make sure you are reading the entire notebook, since it contains a lot of information about your tasks (e.g. regarding the set of certain paramaters or specific computational tricks, etc.), and the written mark downs as well as comments contain a lot of information on how things work together as a whole. \n",
    "\n",
    "**GENERAL NOTE 2**: \n",
    "* Please, when commenting source code, just use English language only. \n",
    "* When describing an observation (for instance, after you have run through your test plan) you may use German language.\n",
    "This applies to all exercises in DIS 21a.1.  \n",
    "\n",
    "---------------------\n",
    "\n",
    "### <font color=\"ce33ff\">DESCRIPTION</font>:\n",
    "\n",
    "This notebook allows you for learning how you effectively setup and use convolutional neural networks (CNN). \n",
    "For this purpose, the classification of the MNIST digits from the earlier exercise is done again. \n",
    "Using a densely (fully) connected ANN in that previous exercise, you have achieved a test accuracy of about 97%. \n",
    "Even though the CNN will be very basic, its accuracy will blow out that of a densely-connected ANN.\n",
    "\n",
    "This notebook shows in a few lines of code what a basic CNN looks alike. \n",
    "Basically, it is a simple stack of `Conv2D` and `MaxPooling2D` layers. \n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "### <font color=\"FFC300\">TASKS</font>:\n",
    "Within this notebook, the tasks that you need to work on are always listed as bullet points below. \n",
    "If a task is more challenging and consists of several steps, this is indicated as well. \n",
    "Make sure you have worked down the task list and commented your doings. \n",
    "This should be done using markdown.<br> \n",
    "<font color=red>Make sure you don't forget to specify your name and your matriculation number in the notebook before submitting it.</font>\n",
    "\n",
    "**YOUR TASKS in this exercise are as follows**:\n",
    "1. import the notebook to Google Colab.\n",
    "2. make sure you specified you name and your matriculation number in the header below my name and date. \n",
    "    * set the date too and remove mine.\n",
    "3. read the entire notebook carefully. \n",
    "    * for better understanding, add comments whereever you feel it necessary.\n",
    "    * run the notebook for the first time and note the result in a markdown table. \n",
    "        * I have provided you with an example of a table in markdown (see below). Make sure you adapt your table accordingly. \n",
    "        * Put the table at the end of the notebook. \n",
    "        * This type of table will be needed in the other exercises as well. Always put it at the end.\n",
    "    \n",
    "| type of method | loss function | optimizer | accuracy |\n",
    "| :-: | :-: | :-: | :-: |\n",
    "| classification | categorical_crossentropy | bamm !|.666\n",
    "\n",
    "4. write the code for 'loading and preparing the MNIST data set'.\n",
    "5. write the code for 'training the CNN'.\n",
    "    * epochs=5\n",
    "    * batch_size=64 \n",
    "6. write the code for 'evaluating the CNN', initially with the given hyperparameters. \n",
    "\n",
    "7. Compare the obtained result to the one you obtained by the densely connected ANN and compute the increase of accuracy in percent.\n",
    "\n",
    "8. write a test plan for testing other hyperparameters. Store the values (also the one from task 7) in a table as the one from above. \n",
    "\n",
    "-----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START OF THE NOTEBOOK CODE\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "### necessary imports\n",
    "others are going to be included as soon as they are needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "tensorflow.keras.__version__\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#C70039\">NOTE: </font>\n",
    "A CNN takes as input tensors of shape `(image_height, image_width, image_channels)` \n",
    "(not including the batch dimension). \n",
    "\n",
    "In this case here, the CNN is configured to process inputs of size `(28, 28, 1)`, which is the format of MNIST grayscale images. This is done by passing the argument `input_shape=(28, 28, 1)` to the first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# the subsequent layers are taking the shape of the previous layers as input shape. \n",
    "# Therefore an explicit specification of the input shape is not needed.\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the architecture of the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of every `Conv2D` and `MaxPooling2D` layer is a 3D tensor of shape `(height, width, channels)`. The width \n",
    "and height dimensions tend to shrink by going deeper into the network. \n",
    "The number of channels is controlled by the first argument passed to the `Conv2D` layers (e.g. 32 or 64).\n",
    "\n",
    "The next step is to feed the last output tensor (of shape `(3, 3, 64)`) into a densely (fully) connected classifier network, i.e. a stack of `Dense` ANN layers. \n",
    "These classifiers do process vectors, which are 1D, whereas our current output is a 3D tensor. \n",
    "\n",
    "So, first the 3D outputs needs to be flattened to 1D, and then a few `Dense` layers are added on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten()) # this could also be done by the reshaping function. You can try it out, if you like.\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a classification of 10 digits again, use a final layer with 10 outputs and a softmax activation (as done before already). \n",
    "Now here's what the final CNN looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `(3, 3, 64)` outputs were flattened into vectors of shape `(576,)`, before going through two `Dense` layers.\n",
    "\n",
    "Now, train the CNN on the MNIST digits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading and preparing the MNIST data set\n",
    "as done before (compare with your old code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training the CNN\n",
    "\n",
    "for the start, take \n",
    "* epochs=5\n",
    "* batch_size=64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.1685 - accuracy: 0.9477\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0452 - accuracy: 0.9858\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.0325 - accuracy: 0.9901\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.0247 - accuracy: 0.9925\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 6s 6ms/step - loss: 0.0193 - accuracy: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d2d699d7e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate the CNN\n",
    "Evaluate the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9937\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026849444955587387"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9937000274658203"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the densely connected ANN had a test accuracy of about 98.2%. \n",
    "\n",
    "The basic CNN has a test accuracy of about 99.4% (double bamm !!!).\n",
    "\n",
    "This is an increase of 1.2 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#C70039\">Include your result table here and reflect a good test plan (see task list)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def mnist_CNN(train_images = train_images, train_labels = train_labels, test_images = test_images, test_labels= test_labels, batch_size_num=64, epochs_num=5):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "    model.add(layers.Flatten()) # this could also be done by the reshaping function. You can try it out, if you like.\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_images, train_labels, epochs=epochs_num, batch_size=batch_size_num)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "    \n",
    "    test_plan_dict = {'method':['binary_classification'], \n",
    "    'loss_function':['categorical_crossentropy'],\n",
    "    'optimizer':['rmsprop'],\n",
    "    'accuracy':[test_acc],\n",
    "    'loss':[test_loss],\n",
    "    'batch_size':[batch_size_num],\n",
    "    'epochs':[epochs_num]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(test_plan_dict)\n",
    "\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plan = pd.DataFrame(columns=['method','loss_function','optimizer','accuracy','loss','batch_size','epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1413 - accuracy: 0.9561\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0434 - accuracy: 0.9869\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0355 - accuracy: 0.9899\n",
      "Epoch 1/2\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.1722 - accuracy: 0.9465\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0461 - accuracy: 0.9852\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0381 - accuracy: 0.9868\n",
      "Epoch 1/2\n",
      "469/469 [==============================] - 6s 11ms/step - loss: 0.2316 - accuracy: 0.9279\n",
      "Epoch 2/2\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0556 - accuracy: 0.9828\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0316 - accuracy: 0.9904\n",
      "Epoch 1/2\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.3583 - accuracy: 0.8866\n",
      "Epoch 2/2\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0710 - accuracy: 0.9779\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0721 - accuracy: 0.9786\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1378 - accuracy: 0.9572\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0440 - accuracy: 0.9868\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0320 - accuracy: 0.9905\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0242 - accuracy: 0.9931\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0200 - accuracy: 0.9942\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0334 - accuracy: 0.9909\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.1789 - accuracy: 0.9445\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0484 - accuracy: 0.9851\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0335 - accuracy: 0.9899\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0255 - accuracy: 0.9922\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0195 - accuracy: 0.9940\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0296 - accuracy: 0.9923\n",
      "Epoch 1/5\n",
      "469/469 [==============================] - 6s 11ms/step - loss: 0.2530 - accuracy: 0.9219\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0559 - accuracy: 0.9825\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0369 - accuracy: 0.9882\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0286 - accuracy: 0.9911\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0224 - accuracy: 0.9931\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0361 - accuracy: 0.9889\n",
      "Epoch 1/5\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.3299 - accuracy: 0.8991\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 5s 22ms/step - loss: 0.0736 - accuracy: 0.9778\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0467 - accuracy: 0.9855\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0346 - accuracy: 0.9893\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0267 - accuracy: 0.9917\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0293 - accuracy: 0.9911\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1350 - accuracy: 0.9578\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0440 - accuracy: 0.9865\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0317 - accuracy: 0.9906\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0248 - accuracy: 0.9930\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0194 - accuracy: 0.9940\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0180 - accuracy: 0.9946\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0155 - accuracy: 0.9956\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0131 - accuracy: 0.9964\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0123 - accuracy: 0.9966\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0115 - accuracy: 0.9969\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0451 - accuracy: 0.9918\n",
      "Epoch 1/10\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.1700 - accuracy: 0.9465\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0466 - accuracy: 0.9860\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0329 - accuracy: 0.9901\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0243 - accuracy: 0.9924\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0189 - accuracy: 0.9943\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0156 - accuracy: 0.9952\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0129 - accuracy: 0.9962\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0105 - accuracy: 0.9967\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0085 - accuracy: 0.9973\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0082 - accuracy: 0.9974\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0444 - accuracy: 0.9894\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 6s 11ms/step - loss: 0.2486 - accuracy: 0.9219\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0574 - accuracy: 0.9826\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0386 - accuracy: 0.9881\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0291 - accuracy: 0.9910\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0233 - accuracy: 0.9928\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0182 - accuracy: 0.9941\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0151 - accuracy: 0.9951\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0122 - accuracy: 0.9962\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0100 - accuracy: 0.9970\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0088 - accuracy: 0.9973\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0345 - accuracy: 0.9917\n",
      "Epoch 1/10\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.3249 - accuracy: 0.8982\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0740 - accuracy: 0.9773\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0477 - accuracy: 0.9848\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0352 - accuracy: 0.9890\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0288 - accuracy: 0.9909\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0224 - accuracy: 0.9933\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0193 - accuracy: 0.9942\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0152 - accuracy: 0.9952\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 5s 22ms/step - loss: 0.0129 - accuracy: 0.9956\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0102 - accuracy: 0.9969\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0308 - accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "epoch_list = [2,5,10]\n",
    "batch_size_list = [32,64,128,256]\n",
    "for epoch_num in epoch_list:\n",
    "    for batch_size_num in batch_size_list:\n",
    "        tr = mnist_CNN(epochs_num=epoch_num, batch_size_num=batch_size_num)\n",
    "        test_plan = pd.concat([test_plan, tr]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | method                | loss_function            | optimizer   |   accuracy |      loss |   batch_size |   epochs |\n",
      "|---:|:----------------------|:-------------------------|:------------|-----------:|----------:|-------------:|---------:|\n",
      "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9896 | 0.0312995 |           32 |        2 |\n",
      "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9872 | 0.0373139 |           64 |        2 |\n",
      "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.983  | 0.0497434 |          128 |        2 |\n",
      "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.971  | 0.0856658 |          256 |        2 |\n",
      "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9896 | 0.0375415 |           32 |        5 |\n",
      "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9918 | 0.0268862 |           64 |        5 |\n",
      "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9927 | 0.023659  |          128 |        5 |\n",
      "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9908 | 0.0253108 |          256 |        5 |\n",
      "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9911 | 0.0464555 |           32 |       10 |\n",
      "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9901 | 0.0536144 |           64 |       10 |\n",
      "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9927 | 0.0343833 |          128 |       10 |\n",
      "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9908 | 0.0322053 |          256 |       10 |\n"
     ]
    }
   ],
   "source": [
    "print(test_plan.to_markdown())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    | method                | loss_function            | optimizer   |   accuracy |      loss |   batch_size |   epochs |\n",
    "|---:|:----------------------|:-------------------------|:------------|-----------:|----------:|-------------:|---------:|\n",
    "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9896 | 0.0312995 |           32 |        2 |\n",
    "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9872 | 0.0373139 |           64 |        2 |\n",
    "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.983  | 0.0497434 |          128 |        2 |\n",
    "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.971  | 0.0856658 |          256 |        2 |\n",
    "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9896 | 0.0375415 |           32 |        5 |\n",
    "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9918 | 0.0268862 |           64 |        5 |\n",
    "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9927 | 0.023659  |          128 |        5 |\n",
    "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9908 | 0.0253108 |          256 |        5 |\n",
    "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9911 | 0.0464555 |           32 |       10 |\n",
    "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9901 | 0.0536144 |           64 |       10 |\n",
    "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9927 | 0.0343833 |          128 |       10 |\n",
    "|  0 | binary_classification | categorical_crossentropy | rmsprop     |     0.9908 | 0.0322053 |          256 |       10 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dis21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:16:53) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "68979083f5533ab07c6381a6af88c3a9d7740bc097ecb5b6319ee072e726248a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
